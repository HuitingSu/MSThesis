---
title: "SSD multi-task lasso vs lasso 1216"
author: "Huiting Su"
date: "April 4, 2018"
output: html_document
---
I want to test if I select random 3 factors, but the 3 factors are important for all tasks, whether the performance will be better.


Design: 1216  
beta ~ N(0,1)  
True factors: same for each task -- first 3 factors.

n: the number of samples ("rows" of data) required.
mu: a vector giving the means of the variables.
Sigma: positive-definite symmetric matrix specifying the covariance matrix of the variables.

X: n x p  N(0, 1)
p: number of factors
l: number of tasks
y: n x l  response
epsilon : n x l  noise
b : p x l. bij is the coef of factor i for task j

```{r, warning= FALSE, message = FALSE, echo=FALSE}
library(MASS)
library(glmnet)
```

## Initialization
### (n=12, p=16) , l = 5
```{r}
n_rep <- 1000
n_sample <- 100000
a <- 5  # absolute value of true factor
SameTrue <- TRUE
#-------------------------
n <- 12
p <- 16
l <- 1
q <- 2  # number of true variables

X <- read.csv("design1226_table4.csv", skip = 7, header = FALSE)
X <- apply(X, 1, gsub, pattern="\\+", replacement= "1", perl=TRUE)
X <- apply(X, 1, gsub, pattern="\\-", replacement= "-1", perl=TRUE)
X <- matrix(as.numeric(X), n, p)
```

### Generate data
```{r}
set.seed(53354111)
# Have 5 different responses
# There are 3 same true var for different tasks, the true vars are randomly chosen

# for every task, we need a vector to set the true vars
gen_data <- function(){
    b <- matrix(0, p, l)
    if(SameTrue == TRUE){       #in this case, the variable is equal for every task
        true_var <- sample(p, q)  
        for(k in 1:q){
            for (j in 1:l){
                vsign = sample(c(-1,1), 1)
                b[true_var[k], j] <- vsign * runif(1, 3, 5) #a  #runif(3, 3, 5)
            }
        }
        
    }else{
        for (j in 1:l){         #for each task, sample different true factors
            true_var <- sample(p, q)
            b[true_var, j] <- a  #runif(3, 3, 5)
        }
    }
    
y <- X %*% b
# epsilon is the gaussian error. dimension: n * l.
epsilon <- matrix(rnorm(n * l), n, l)

y <- y + epsilon
return(list(y,b))
}
```

### Calculate Probability
```{r}
lambda = 1
sigma = 1
I = diag(n)
XA <- X[, true_var]
XC <- X[, -true_var]
bA <- b[true_var,]
sgnbA <- sign(bA)
inv = solve(t(XA) %*% XA)

R <- t(XC) %*% XA %*% inv %*% sgnbA
P <- XA %*% inv %*% t(XA)
D <- lambda/2 * inv %*% sgnbA

#U <- mvrnorm(n = n_sample, R, 4*sigma^2/lambda^2 * t(XC) %*% (I-P) %*% t(I-P) %*% XC)
#V <- mvrnorm(n = n_sample, D, sigma^2 * inv %*% t(XA) %*% XA %*% t(inv))  # the later is I

U <- mvrnorm(n = n_sample, R, sigma^2/lambda^2 * t(XC) %*% (I-P) %*% XC)
V <- matrix(mvrnorm(n = n_sample * q, D, sigma^2 * inv), n_sample, q)

P1 <- U >= -1 & U <= 1   # a vector showing every rep
P1 <- rowSums(P1) == (p - q)
Vpos = matrix(sapply(V,max,0),n_sample, q)
Vneg = matrix(sapply(V,min,0),n_sample, q)
P2 <- rowSums(bA >= Vpos | bA <= Vneg) == q

PSC = sum(P1 & P2)/n_sample

```

### Use my own LASSO to estimated the probability. Glmnet may use some different objective function.
Define the functions:
```{r}
soft_threshold <- function(w, th){
    if(abs(w) < th){
        return(0)
    }else{
        return(sign(w)*(abs(w)-th))
    }
}

get_residual <- function(w, dim){
    w[dim] <- 0
    Y_pred <- X %*% w
    return(y - Y_pred)
}

coor_descent <-  function(w0, epsilon, lambda){
    w = w0
    w_prev = w0 + epsilon + 1
    while(sum(abs(w-w_prev) > epsilon)) {
        w_prev = w
        for(d in 1:length(w0)){
            rd = get_residual(w, d)
            xd = X[,d]
            w_OLS = t(xd) %*% rd / t(xd) %*% xd
            w[d] = soft_threshold(w_OLS, lambda/t(xd)%*%xd)
        } 
    }
    return(w)
}
```

```{r}
PSC_hat = numeric(n_rep)
data = gen_data()
y = data[[1]]
b = data[[2]]
for(i in 1:n_rep){
    #data = gen_data()
    #y = data[[1]]
    #b = data[[2]]
    b0 = rnorm(p)
    b_lasso = coor_descent(b0, epsilon = 0.1, lambda = 8)
    PSC_hat[i] = sum(sign(b_lasso) == sign(b)) == p
}
sum(PSC_hat)/n_rep
```

### Calculate Probability for different b
```{r}
lambda = 1
sigma = 1
PSC_hat = numeric(n_rep)
for(i in 1:n_rep){
    data = gen_data()
    y = data[[1]]
    b = data[[2]]
    
I = diag(n)
XA <- X[, true_var]
XC <- X[, -true_var]
bA <- b[true_var,]
sgnbA <- sign(bA)
inv = solve(t(XA) %*% XA)

R <- t(XC) %*% XA %*% inv %*% sgnbA
P <- XA %*% inv %*% t(XA)
D <- lambda/2 * inv %*% sgnbA

U <- mvrnorm(n = n_sample, R, 4*sigma^2/lambda^2 * t(XC) %*% (I-P) %*% t(I-P) %*% XC)
V <- mvrnorm(n = n_sample, D, sigma^2 * inv %*% t(XA) %*% XA %*% t(inv))  # the later is I

#U <- mvrnorm(n = n_sample, R, sigma^2/lambda^2 * t(XC) %*% (I-P) %*% XC)
#V <- mvrnorm(n = n_sample, D, sigma^2 * inv)

P1 <- U >= -1 & U <= 1   # a vector showing every rep
P1 <- rowSums(P1) == (p - q)
Vpos = matrix(sapply(V,max,0),n_sample, q)
Vneg = matrix(sapply(V,min,0),n_sample, q)
P2 <- rowSums(bA >= Vpos | bA <= Vneg) == q
    PSC_hat[i] = sum(P1 & P2)/n_sample
}
sum(PSC_hat)/n_rep
```


It is not neccessary to write in a multi-variate nomal









