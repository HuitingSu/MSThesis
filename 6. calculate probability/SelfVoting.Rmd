### Test Probability and compare with the probability in paper.
```{r}
library(MASS)
library(glmnet)
```

```{r}
n <- 12
p <- 16
l <- 1
q <- 3  # number of true variables

X <- read.csv("design1226_table4.csv", skip = 7, header = FALSE)
X <- apply(X, 1, gsub, pattern="\\+", replacement= "1", perl=TRUE)
X <- apply(X, 1, gsub, pattern="\\-", replacement= "-1", perl=TRUE)
X <- matrix(as.numeric(X), n, p)

sigma <- 1
b <- matrix(0,p,l)
true_var <- c(1,3,9)
b[true_var] <- 2
y <- X %*% b
# epsilon is the gaussian error. dimension: n * l.
epsilon <- matrix(rnorm(n * l), n, l)
y <- y + epsilon
```

```{r}
estimate_PSC <- function(true_var, b, lambda){
    n_sample = 30000
    q = length(true_var)
    I = diag(n)
    XA <- X[, true_var]
    XC <- X[, -true_var]
    bA <- b[true_var,]
    sgnbA <- sign(bA)
    inv = solve(t(XA) %*% XA)
    
    R <- t(XC) %*% XA %*% inv %*% sgnbA
    P <- XA %*% inv %*% t(XA)
#    D <- lambda/2 * inv %*% sgnbA
    D <- lambda*n * inv %*% sgnbA
    
#    U <- mvrnorm(n = n_sample, R, 4*sigma^2/lambda^2 * t(XC) %*% (I-P) %*% t(I-P) %*% XC)
#    V <- mvrnorm(n = n_sample, D, sigma^2 * inv %*% t(XA) %*% XA %*% t(inv))  # the later is I
    
    U <- mvrnorm(n = n_sample, R, sigma^2/(lambda^2 * n^2) * t(XC) %*% (I-P) %*% t(I-P) %*% XC)
    V <- mvrnorm(n = n_sample, D, sigma^2 * inv %*% t(XA) %*% XA %*% t(inv))  # the later is I
    
    P1 <- U >= -1 & U <= 1   # a vector showing every rep
    P1 <- rowSums(P1) == (p - q)
    Vpos = matrix(sapply(V,max,0),n_sample, q)
    Vneg = matrix(sapply(V,min,0),n_sample, q)
    P2 <- rowSums(bA >= Vpos | bA <= Vneg) == q
    
    PSC = sum(P1 & P2)/n_sample
    return(PSC)
}
```

This result is consistent with the result in paper.

Multiply 1/2n to the loss function. Then the result is consistent.
```{r}
result = sapply(seq(0.1, 3, by=0.1), estimate_PSC, true_var=true_var, b= b)
plot(result)
fit = glmnet(X,y,intercept = FALSE)
coef(fit, s=1.4)
```

Use LASSO to screen when at different lambda. 

```{r}
set.seed(72022)
lambda0 = 0
lambda = 1.5
while(abs(lambda - lambda0) > 0.01){
    lambda0 = lambda
#    b_lasso = coor_descent(rnorm(p), epsilon = 0.001, lambda = lambda0)
    fit = glmnet(X, y, intercept = FALSE)
    b_lasso = coef(fit, s = lambda0)[-1]
    estimated_A = which(b_lasso != 0)
    X_Ahat = X[,estimated_A]
    estimated_b = solve(t(X_Ahat) %*% X_Ahat) %*% t(X_Ahat) %*% y
    b_current = matrix(0,p,l)
    b_current[estimated_A,] = estimated_b
    lambda <- optim(lambda, estimate_PSC, method= 'L-BFGS-B', lower = 0, true_var = estimated_A, b = b_current)[[1]]
}

```


















