mt_SC <<- c(mt_SC, sum(sign(w) == sign(mt_beta)) == p*l )
lasso_SC <<- c(lasso_SC, sum(sign(w) == sign(lasso_beta)) == p*l )
}
sums <- 0
pp <- 16
for(i in 1:(pp-1))
for(j in (i+1):pp){
s <- t(X[,i]) %*% X[,j]
sums <- sums + s^2
}
sums <- sums * 2/ pp /(pp-1)
set.seed(87293)
for(ii in 1:1){
getXy()
compare()
}
mt_fit = glmnet(X, y, family = "mgaussian")
mt_beta = numeric()
for(i in 1:l){
mt_beta = cbind(mt_beta, paste(coef(cv.mt_fit)$y, i, sep=''))
}
cv.mt_fit = cv.glmnet(X, y, family = "mgaussian", intercept = FALSE)
for(i in 1:l){
mt_beta = cbind(mt_beta, paste(coef(cv.mt_fit)$y, i, sep=''))
}
mt_beta = mt_beta[-1,]
print(mt_beta)
paste(coef(cv.mt_fit)$y, i, sep='')
paste('coef(cv.mt_fit)$y', i, sep='')
tmp = paste('coef(cv.mt_fit)$y', i, sep='')
tmp
mt_beta = cbind(mt_beta,tmp)
mt_beta = numeric()
for(i in 1:l){
mt_beta = cbind(mt_beta, paste('coef(cv.mt_fit)$y', i, sep=''))
}
mt_beta
eval(paste('coef(cv.mt_fit)$y', i, sep=''))
eval(parse(text = "paste('coef(cv.mt_fit)$y', i, sep='')"))
tmp = eval(parse(text = "paste('coef(cv.mt_fit)$y', i, sep='')"))
tmp
eval(parse(text="coef(cv.mt_fit)$y5"))
tmp
eval(parse(text=tmp))
mt_beta = numeric()
for(i in 1:l){
mt_beta = cbind(mt_beta,  eval(parse(text = paste('coef(cv.mt_fit)$y', i, sep=''))) )
}
mt_beta = mt_beta[-1,]
print(mt_beta)
mt_beta = numeric()
for(i in 1:l){
mt_beta = cbind(mt_beta,  eval(parse(text = paste('coef(cv.mt_fit)$y', i, sep=''))) )
}
print(mt_beta)
mt_beta = cbind(
coef(cv.mt_fit)$y1,
coef(cv.mt_fit)$y2,
coef(cv.mt_fit)$y3,
coef(cv.mt_fit)$y4,
coef(cv.mt_fit)$y5
)
print(mt_beta)
lasso_beta = numeric()
for(i in 1:l){
lasso_beta = cbind(lasso_beta,  eval(parse(text = paste('coef(cv.fit', i,')', sep=''))) )
}
cv.fit1 = cv.glmnet(X, y[, 1], intercept = FALSE)
cv.fit2 = cv.glmnet(X, y[, 2], intercept = FALSE)
cv.fit3 = cv.glmnet(X, y[, 3], intercept = FALSE)
cv.fit4 = cv.glmnet(X, y[, 4], intercept = FALSE)
cv.fit5 = cv.glmnet(X, y[, 5], intercept = FALSE)
lasso_beta = cbind(coef(cv.fit1),
coef(cv.fit2),
coef(cv.fit3),
coef(cv.fit4),
coef(cv.fit5))
print(lasso_beta)
lasso_beta = numeric()
for(i in 1:l){
lasso_beta = cbind(lasso_beta,  eval(parse(text = paste('coef(cv.fit', i,')', sep=''))) )
}
print(lasso_beta)
compare <- function() {
mt_fit = glmnet(X, y, family = "mgaussian")
#plot(mt_fit, type.coef = "2norm", label = TRUE)
## Use Cross Validation to select $\lambda$, and compare.
cv.mt_fit = cv.glmnet(X, y, family = "mgaussian", intercept = FALSE)
cv.fit1 = cv.glmnet(X, y[, 1], intercept = FALSE)
cv.fit2 = cv.glmnet(X, y[, 2], intercept = FALSE)
cv.fit3 = cv.glmnet(X, y[, 3], intercept = FALSE)
cv.fit4 = cv.glmnet(X, y[, 4], intercept = FALSE)
cv.fit5 = cv.glmnet(X, y[, 5], intercept = FALSE)
# Option grouped=FALSE enforced in cv.glmnet, since < 3 observations per fold
# If grouped=FALSE, an error matrix is built up at the observation level from the predictions from the nfold fits, and then summarized
#plot(cv.mt_fit)
#plot(cv.fit1)
#plot(cv.fit2)
#plot(cv.fit3)
# multi-task
mt_beta = numeric()
for(i in 1:l){
mt_beta = cbind(mt_beta,  eval(parse(text = paste('coef(cv.mt_fit)$y', i, sep=''))) )
}
mt_beta = mt_beta[-1,]
print(mt_beta)
# lasso for each response
lasso_beta = numeric()
for(i in 1:l){
lasso_beta = cbind(lasso_beta,  eval(parse(text = paste('coef(cv.fit', i,')', sep=''))) )
}
lasso_beta = lasso_beta[-1,]
print(lasso_beta)
# get whether correct selection
mt_OC <<- c(mt_OC, sum(as.logical(w) == as.logical(mt_beta)) == p*l )
lasso_OC <<- c(lasso_OC, sum(as.logical(w) == as.logical(lasso_beta)) == p * l)
mt_SC <<- c(mt_SC, sum(sign(w) == sign(mt_beta)) == p*l )
lasso_SC <<- c(lasso_SC, sum(sign(w) == sign(lasso_beta)) == p*l )
}
set.seed(87293)
for(ii in 1:1){
getXy()
compare()
}
mt_wRSS
lasso_wRSS
mt_correct
lasso_correct
cat(mean(mt_wRSS), mean(lasso_wRSS), mean(mt_correct), mean(lasso_correct))
#print(rbind(t.test(mt_wRSS)$conf.int[1:2], t.test(lasso_wRSS)$conf.int[1:2], t.test(mt_correct)$conf.int[1:2], t.test(lasso_correct)$conf.int[1:2]))
set.seed(87293)
for(ii in 1:1){
getXy()
compare()
}
print(mt_OC)
print(lasso_OC)
cat(mean(mt_wRSS), mean(lasso_wRSS), mean(mt_correct), mean(lasso_correct))
#print(rbind(t.test(mt_wRSS)$conf.int[1:2], t.test(lasso_wRSS)$conf.int[1:2], t.test(mt_correct)$conf.int[1:2], t.test(lasso_correct)$conf.int[1:2]))
set.seed(87293)
for(ii in 1:1000){
getXy()
compare()
}
set.seed(87293)
for(ii in 1:1000){
getXy()
compare()
}
#set.seed(65587)
n_rep <- 100
a <- 5  # absolute value of true factor
n <- 12
p <- 16
l <- 5
q <- 3
X <- read.csv("design1226.csv", skip = 7, header = FALSE)
X <- apply(X, 1, gsub, pattern="\\+", replacement= "1", perl=TRUE)
X <- apply(X, 1, gsub, pattern="\\-", replacement= "-1", perl=TRUE)
X <- matrix(as.numeric(X), n, p)
lasso_OC <<- numeric()
mt_OC <<- numeric()
lasso_SC <<- numeric()
mt_SC <<- numeric()
getXy <- function(){
# Have 5 different responses
# There are 3 same true var for different tasks, the true vars are randomly chosen
# for every task, we need a vector to set the true vars
w <<- matrix(0, p, l)
true_var <- c(1, 2)    #sample(p, q)  #c(1, 2, 3)   #
for (j in 1:l) {
w[true_var, j] <<- a # runif(3, 3, 5)
}
print(w)
y <<- X %*% w
# epsilon is the gaussian error. dimension: n * l.
epsilon <- matrix(rnorm(n * l), n, l)
y <<- y + epsilon
}
compare <- function() {
mt_fit = glmnet(X, y, family = "mgaussian")
#plot(mt_fit, type.coef = "2norm", label = TRUE)
## Use Cross Validation to select $\lambda$, and compare.
cv.mt_fit = cv.glmnet(X, y, family = "mgaussian", intercept = FALSE)
cv.fit1 = cv.glmnet(X, y[, 1], intercept = FALSE)
cv.fit2 = cv.glmnet(X, y[, 2], intercept = FALSE)
cv.fit3 = cv.glmnet(X, y[, 3], intercept = FALSE)
cv.fit4 = cv.glmnet(X, y[, 4], intercept = FALSE)
cv.fit5 = cv.glmnet(X, y[, 5], intercept = FALSE)
# Option grouped=FALSE enforced in cv.glmnet, since < 3 observations per fold
# If grouped=FALSE, an error matrix is built up at the observation level from the predictions from the nfold fits, and then summarized
#plot(cv.mt_fit)
#plot(cv.fit1)
#plot(cv.fit2)
#plot(cv.fit3)
# multi-task
mt_beta = numeric()
for(i in 1:l){
mt_beta = cbind(mt_beta,  eval(parse(text = paste('coef(cv.mt_fit)$y', i, sep=''))) )
}
mt_beta = mt_beta[-1,]
#####print(mt_beta)
# lasso for each response
lasso_beta = numeric()
for(i in 1:l){
lasso_beta = cbind(lasso_beta,  eval(parse(text = paste('coef(cv.fit', i,')', sep=''))) )
}
lasso_beta = lasso_beta[-1,]
####print(lasso_beta)
# get whether correct selection
mt_OC <<- c(mt_OC, sum(as.logical(w) == as.logical(mt_beta)) == p*l )
lasso_OC <<- c(lasso_OC, sum(as.logical(w) == as.logical(lasso_beta)) == p * l)
mt_SC <<- c(mt_SC, sum(sign(w) == sign(mt_beta)) == p*l )
lasso_SC <<- c(lasso_SC, sum(sign(w) == sign(lasso_beta)) == p*l )
}
set.seed(87293)
for(ii in 1:nrep){
getXy()
compare()
}
set.seed(87293)
for(ii in 1:n_rep){
getXy()
compare()
}
getXy <- function(){
# Have 5 different responses
# There are 3 same true var for different tasks, the true vars are randomly chosen
# for every task, we need a vector to set the true vars
w <<- matrix(0, p, l)
true_var <- c(1, 2)    #sample(p, q)  #c(1, 2, 3)   #
for (j in 1:l) {
w[true_var, j] <<- a # runif(3, 3, 5)
}
#######print(w)
y <<- X %*% w
# epsilon is the gaussian error. dimension: n * l.
epsilon <- matrix(rnorm(n * l), n, l)
y <<- y + epsilon
}
set.seed(87293)
for(ii in 1:n_rep){
getXy()
compare()
}
#print(mt_OC)
#print(lasso_OC)
cat(mean(mt_OC), mean(lasso_OC), mean(mt_SC), mean(lasso_SC))
#print(rbind(t.test(mt_wRSS)$conf.int[1:2], t.test(lasso_wRSS)$conf.int[1:2], t.test(mt_correct)$conf.int[1:2], t.test(lasso_correct)$conf.int[1:2]))
#library(MASS)
library(glmnet)
#set.seed(65587)
n_rep <- 100
a <- 5  # absolute value of true factor
n <- 12
p <- 16
l <- 5
q <- 3
X <- read.csv("design1226.csv", skip = 7, header = FALSE)
X <- apply(X, 1, gsub, pattern="\\+", replacement= "1", perl=TRUE)
X <- apply(X, 1, gsub, pattern="\\-", replacement= "-1", perl=TRUE)
X <- matrix(as.numeric(X), n, p)
lasso_OC <<- numeric()
mt_OC <<- numeric()
lasso_SC <<- numeric()
mt_SC <<- numeric()
getXy <- function(){
# Have 5 different responses
# There are 3 same true var for different tasks, the true vars are randomly chosen
# for every task, we need a vector to set the true vars
w <<- matrix(0, p, l)
true_var <- c(1, 2)    #sample(p, q)  #c(1, 2, 3)   #
for (j in 1:l) {
w[true_var, j] <<- a # runif(3, 3, 5)
}
#######print(w)
y <<- X %*% w
# epsilon is the gaussian error. dimension: n * l.
epsilon <- matrix(rnorm(n * l), n, l)
y <<- y + epsilon
}
compare <- function() {
mt_fit = glmnet(X, y, family = "mgaussian")
#plot(mt_fit, type.coef = "2norm", label = TRUE)
## Use Cross Validation to select $\lambda$, and compare.
cv.mt_fit = cv.glmnet(X, y, family = "mgaussian", intercept = FALSE)
cv.fit1 = cv.glmnet(X, y[, 1], intercept = FALSE)
cv.fit2 = cv.glmnet(X, y[, 2], intercept = FALSE)
cv.fit3 = cv.glmnet(X, y[, 3], intercept = FALSE)
cv.fit4 = cv.glmnet(X, y[, 4], intercept = FALSE)
cv.fit5 = cv.glmnet(X, y[, 5], intercept = FALSE)
# Option grouped=FALSE enforced in cv.glmnet, since < 3 observations per fold
# If grouped=FALSE, an error matrix is built up at the observation level from the predictions from the nfold fits, and then summarized
#plot(cv.mt_fit)
#plot(cv.fit1)
#plot(cv.fit2)
#plot(cv.fit3)
# multi-task
mt_beta = numeric()
for(i in 1:l){
mt_beta = cbind(mt_beta,  eval(parse(text = paste('coef(cv.mt_fit)$y', i, sep=''))) )
}
mt_beta = mt_beta[-1,]
#####print(mt_beta)
# lasso for each response
lasso_beta = numeric()
for(i in 1:l){
lasso_beta = cbind(lasso_beta,  eval(parse(text = paste('coef(cv.fit', i,')', sep=''))) )
}
lasso_beta = lasso_beta[-1,]
####print(lasso_beta)
# get whether correct selection
mt_OC <<- c(mt_OC, sum(as.logical(w) == as.logical(mt_beta)) == p*l )
lasso_OC <<- c(lasso_OC, sum(as.logical(w) == as.logical(lasso_beta)) == p * l)
mt_SC <<- c(mt_SC, sum(sign(w) == sign(mt_beta)) == p*l )
lasso_SC <<- c(lasso_SC, sum(sign(w) == sign(lasso_beta)) == p*l )
}
set.seed(87293)
for(ii in 1:n_rep){
getXy()
compare()
}
#print(mt_OC)
#print(lasso_OC)
cat(mean(mt_OC), mean(lasso_OC), mean(mt_SC), mean(lasso_SC))
#print(rbind(t.test(mt_wRSS)$conf.int[1:2], t.test(lasso_wRSS)$conf.int[1:2], t.test(mt_correct)$conf.int[1:2], t.test(lasso_correct)$conf.int[1:2]))
View(w)
View(X)
X[,1] + X[,2] + X[,3]
X[,4]
X[,1] + X[,2] + X[,4]
X[,1] + X[,2] + X[,3] - X[,4]
X[,1] + X[,2] + X[,3] - X[,5]
X[,1] + X[,2] + X[,3] - X[,6]
X[,1] + X[,2] + X[,3] - X[,7]
X[,1] + X[,2] + X[,3] - X[,8]
X[,1] + X[,2] + X[,3] - X[,9]
X[,1] + X[,2] + X[,3] - X[,10]
X[,1] + X[,2] + X[,3] - X[,111]
X[,1] + X[,2] + X[,3] - X[,11]
X[,1] + X[,2] + X[,3] - X[,12]
X[,1] + X[,2] + X[,4] - X[,3]
X[,1] + X[,2] + X[,4] - X[,5]
sums <- 0
pp <- 16
for(a1 in 1:(pp-1))
for(a2 in (a1+1):pp){
XC <- X[,-c(a1, a2)]
XA <- X[, c(a1, a2)]
invXA <- solve(t(XA) %*% XA)
s <- t(XC) %*% XA %*% invXA %*% invXA %*% t(XA) %*% XC
#cat(a1, a2, sum(diag(s)), "\n")
sums <- sums + sum(diag(s))
}
sums <- 0
pp <- 16
for(a1 in 1:(pp-2))
for(a2 in (a1+1):(pp-1))
for(a3 in (a2+1):(pp-1)){
XC <- X[,-c(a1, a2, a3)]
XA <- X[, c(a1, a2, a3)]
invXA <- solve(t(XA) %*% XA)
s <- t(XC) %*% XA %*% invXA %*% invXA %*% t(XA) %*% XC
cat(a1, a2, a3, sum(diag(s)), "\n")
sums <- sums + sum(diag(s))
}
pp <- 16
for(a1 in 1:(pp-1))
for(a2 in (a1+1):pp)
for (b in 1:pp){
if(a1 != b && a2 != b){
X[,a1]+X[,a2]-X[,b]
}
}
pp <- 16
for(a1 in 1:(pp-1))
for(a2 in (a1+1):pp)
for(b in 1:pp){
if(a1 != b && a2 != b){
X[,a1]+X[,a2]-X[,b]
}
}
pp <- 16
diff <- numeric()
for(a1 in 1:(pp-1))
for(a2 in (a1+1):pp)
for(b in 1:pp){
if(a1 != b && a2 != b){
diff <- c(diff, X[,a1]+X[,a2]-X[,b])
}
}
X[,a1]+X[,a2]-X[,b]
pp <- 16
diff <- numeric()
for(a1 in 1:(pp-1))
for(a2 in (a1+1):pp)
for(b in 1:pp){
if(a1 != b && a2 != b){
diff <- cbind(diff, X[,a1]+X[,a2]-X[,b])
}
}
View(diff)
pp <- 16
diff <- numeric()
for(a1 in 1:(pp-1))
for(a2 in (a1+1):pp)
for(a3 in (a2+1):(pp-1))
for(b in 1:pp){
if(a1 != b && a2 != b && a3 != b){
diff <- cbind(diff, X[,a1]+X[,a2]+X[,a3]-X[,b])
}
}
pp <- 16
diff <- numeric()
for(a1 in 1:(pp-2))
for(a2 in (a1+1):(pp-1))
for(a3 in (a2+1):(pp-1))
for(b in 1:pp){
if(a1 != b && a2 != b && a3 != b){
diff <- cbind(diff, X[,a1]+X[,a2]+X[,a3]-X[,b])
}
}
View(diff)
pp <- 16
diff2 <- numeric()
for(a1 in 1:(pp-1))
for(a2 in (a1+1):pp)
for(b in 1:pp){
if(a1 != b && a2 != b){
diff2 <- cbind(diff, X[,a1]+X[,a2]-X[,b])
}
}
pp <- 16
diff3 <- numeric()
for(a1 in 1:(pp-2))
for(a2 in (a1+1):(pp-1))
for(a3 in (a2+1):(pp-1))
for(b in 1:pp){
if(a1 != b && a2 != b && a3 != b){
diff3 <- cbind(diff, X[,a1]+X[,a2]+X[,a3]-X[,b])
}
}
16*15/2*14
16*15*14/3/2*13
dim(diff2)
dim(diff3)
14*13*12*13
pp <- 16
diff2 <- numeric()
for(a1 in 1:(pp-1))
for(a2 in (a1+1):pp)
for(b in 1:pp){
if(a1 != b && a2 != b){
diff2 <- cbind(diff, X[,a1]+X[,a2]-X[,b])
}
}
pp <- 16
diff3 <- numeric()
for(a1 in 1:(pp-2))
for(a2 in (a1+1):(pp-1))
for(a3 in (a2+1):(pp-1))
for(b in 1:pp){
if(a1 != b && a2 != b && a3 != b){
diff3 <- cbind(diff, X[,a1]+X[,a2]+X[,a3]-X[,b])
}
}
dim(diff3)
pp <- 16
diff2 <- numeric()
for(a1 in 1:(pp-1))
for(a2 in (a1+1):pp)
for(b in 1:pp){
if(a1 != b && a2 != b){
diff2 <- cbind(diff2, X[,a1]+X[,a2]-X[,b])
}
}
pp <- 16
diff3 <- numeric()
for(a1 in 1:(pp-2))
for(a2 in (a1+1):(pp-1))
for(a3 in (a2+1):(pp-1))
for(b in 1:pp){
if(a1 != b && a2 != b && a3 != b){
diff3 <- cbind(diff3, X[,a1]+X[,a2]+X[,a3]-X[,b])
}
}
dim(diff2)
dim(diff3)
pp <- 16
diff3 <- numeric()
for(a1 in 1:(pp-2))
for(a2 in (a1+1):(pp-1))
for(a3 in (a2+1):pp)
for(b in 1:pp){
if(a1 != b && a2 != b && a3 != b){
diff3 <- cbind(diff3, X[,a1]+X[,a2]+X[,a3]-X[,b])
}
}
dim(diff3)
View(diff3)
#library(MASS)
library(glmnet)
n_rep <- 100
a <- 5  # absolute value of true factor
SameTrue <- TRUE
#-------------------------
n <- 12
p <- 16
l <- 5
q <- 2  # number of true variables
X <- read.csv("design1226.csv", skip = 7, header = FALSE)
getwd()
