---
title: "Multi-task Lasso Sample"
author: "Huiting Su"
output: html_document
---

1.Large scale problems: number of factors. Number of responses
2.Different correlation structure of the responses
3.Self-voting

```{r, warning=FALSE, message=FALSE}
library(glmnet)
```

```{r}
set.seed(65587)
x <- matrix(rnorm(10000), 2500, 4)
#x <- as.data.frame(x)
#colnames(x) <- c('x1', 'x2', 'x3', 'x4')

y1 <- 0.9*x[,1] + 0.00*x[,2] + 1.2*x[,3] + 0.3*x[,4] + 0.1*rnorm(2500)
y2 <- 1.1*x[,1] + 0.02*x[,2] + 0.8*x[,3] + 0.4*x[,4] + 0.1*rnorm(2500)
y3 <- 0.9*x[,1] + 0.01*x[,2] + 1.3*x[,3] + 0.5*x[,4] + 0.1*rnorm(2500)
y <- cbind(y1, y2, y3)
```

```{r}
mfit = glmnet(x, y, family = "mgaussian")
plot(mfit,type.coef="2norm", label = TRUE)
```

Extract coefficients at a single value of lambda.(manually chose the lambda)
```{r}
#coef(mfit, s=1)  
cbind(coef(mfit, s=0.1)$y1, coef(mfit, s=0.1)$y2, coef(mfit, s=0.1)$y3)    
#coef(mfit, s=0.001)
```
According to the result, x2 is never chosen. When regulation is large, x4 is also not chosen. x1 and x3 are cosidered to be important. 

```{r}
fit1 = glmnet(x, y[,1])
fit2 = glmnet(x, y[,2])
fit3 = glmnet(x, y[,3])
cbind(coef(fit1, s=0.1), coef(fit2, s=0.1),coef(fit3, s=0.1))  
```


## Use Cross Validation to select $\lambda$, and compare.
```{r}
cv.mfit = cv.glmnet(x, y, family = "mgaussian")
cv.fit1 = cv.glmnet(x, y[,1])
cv.fit2 = cv.glmnet(x, y[,2])
cv.fit3 = cv.glmnet(x, y[,3])
plot(cv.mfit)
plot(cv.fit1)
plot(cv.fit2)
plot(cv.fit3)
```

```{r}
cbind(coef(cv.mfit)$y1, coef(cv.mfit)$y2, coef(cv.mfit)$y3)
cbind(coef(cv.fit1), coef(cv.fit2), coef(cv.fit3))
```




